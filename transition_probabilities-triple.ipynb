{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from datetime import timedelta\r\n",
        "import datetime\r\n",
        "import sklearn.metrics as skm\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1681580469966
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Siirtymätodennäköisyyksien analysointia kolmivuorotasolla"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_day = pd.Timestamp('2018-10-01')\r\n",
        "start = pd.Timestamp('2017-01-01T00')\r\n",
        "end = pd.Timestamp('2019-12-31T00')\r\n",
        "\r\n",
        "const1 = 26288\r\n",
        "const2 = 26280\r\n",
        "\r\n",
        "const3 = 11160\r\n",
        "const4 = 11152"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681580470448
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\r\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\r\n",
        "\r\n",
        "def mean_absolute_error(y_true, y_pred):\r\n",
        "    return np.mean(np.abs(y_true - y_pred))\r\n",
        "\r\n",
        "def mean_squared_error(y_true, y_pred):\r\n",
        "    return np.mean(np.power((y_true - y_pred), 2))\r\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681580470853
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lasten päivystys"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subscription_id = '4371739e-d07f-42d5-a3a6-efa120c1e246'\r\n",
        "resource_group = 'husfd-tu-dip-potilasvirrat'\r\n",
        "workspace_name = 'husfd-tu-dip-potilasvirrat-ml'\r\n",
        "\r\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\r\n",
        "\r\n",
        "dataset = Dataset.get_by_name(workspace, name='uranus27_1')\r\n",
        "features = ['kaynti_numero', 'potilasnumero', 'henkilotunnus', 'alkuhetki', 'loppuhetki',\r\n",
        "       'vo_toimipiste_nimi', 'kayntityyppi_selite', 'varaustyyppi_selite',\r\n",
        "       'mista_tuli_selite', 'res_koodi', 'res_selite', 'jh_selite', \r\n",
        "       'jatkoh_laitos_nimi', 'jatkoh_toimipiste_nimi']\r\n",
        "df = dataset.to_pandas_dataframe()[features]\r\n",
        "df.replace(\"\", float(\"NaN\"), inplace=True)\r\n",
        "df.dropna(subset=['alkuhetki', 'loppuhetki'], inplace=True)\r\n",
        "df.drop_duplicates(subset='kaynti_numero', inplace=True)\r\n",
        "df = df[df['varaustyyppi_selite'] != 'PÄIV PKL soitto']\r\n",
        "df = df[(df['kayntityyppi_selite'] != 'Hoitokäynti') & (df['kayntityyppi_selite'] != 'Ohjattu muualle') & \r\n",
        "       (df['kayntityyppi_selite'] !='HYKSin Oy:n potilas') & (df['kayntityyppi_selite'] != 'Sarjahoitokäynti') & \r\n",
        "       (df['kayntityyppi_selite'] != 'Ensikäynti')]\r\n",
        "df = df[(df.alkuhetki >= start) & (df.alkuhetki < end)]\r\n",
        "df_train = df\r\n",
        "df_test = df[df.alkuhetki >= train_test_day]\r\n",
        "pd.set_option('display.max_columns', None)\r\n",
        "df_train = df_train.sort_values(by='alkuhetki')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681580474066
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['alkuhetki'] = pd.to_datetime(df_train['alkuhetki'], format=\"%Y-%m-%d %H:%M:%S\")\r\n",
        "df_train['loppuhetki'] = pd.to_datetime(df_train['loppuhetki'], format=\"%Y-%m-%d %H:%M:%S\")\r\n",
        "df_train = df_train[df_train['alkuhetki'] <= df_train['loppuhetki']]\r\n",
        "df_train['aikaväli'] = pd.arrays.IntervalArray.from_arrays(left = df_train['alkuhetki'], right = df_train['loppuhetki'], closed='neither')\r\n",
        "df_train['palveluaika'] = ((df_train['loppuhetki'] - df_train['alkuhetki']).astype('timedelta64[s]') / 3600)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681580474701
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['alkuhetki'] = pd.to_datetime(df_test['alkuhetki'], format=\"%Y-%m-%d %H:%M:%S\")\r\n",
        "df_test['loppuhetki'] = pd.to_datetime(df_test['loppuhetki'], format=\"%Y-%m-%d %H:%M:%S\")\r\n",
        "df_test = df_test[df_test['alkuhetki'] <= df_test['loppuhetki']]\r\n",
        "df_test['aikaväli'] = pd.arrays.IntervalArray.from_arrays(left = df_test['alkuhetki'], right = df_test['loppuhetki'], closed='neither')\r\n",
        "df_test['palveluaika'] = ((df_test['loppuhetki'] - df_test['alkuhetki']).astype('timedelta64[s]') / 3600)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681580477915
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aika = train_test_day\r\n",
        "span_day = pd.DataFrame(data={'time':[aika + timedelta(hours=x) for x in range(0, const3, 8)]})\r\n",
        "timestamp_day = [aika + timedelta(hours=x) for x in range(0, const4, 8)]\r\n",
        "df_test_day = pd.DataFrame(data={'time':timestamp_day})\r\n",
        "df_test_day['weekday'] = df_test_day['time'].dt.weekday\r\n",
        "df_test_day['month'] = df_test_day['time'].dt.month\r\n",
        "df_test_day['timespan'] = pd.arrays.IntervalArray.from_arrays(left = span_day['time'][0:-1], right = span_day['time'][1:], closed='left')\r\n",
        "df_test_day['patient_count'] = pd.DataFrame([pd.arrays.IntervalArray(df_test_day['timespan']).overlaps(b) for b in df_test['aikaväli']]).sum()\r\n",
        "\r\n",
        "for t in range(len(df_test_day['timespan'])):\r\n",
        "    sum = 0\r\n",
        "    for a, b in zip(df_test['aikaväli'], df_test['loppuhetki']):\r\n",
        "        if ((df_test_day.loc[t, 'timespan'].overlaps(a)) == True) & ((b in df_test_day.loc[t, 'timespan']) == False):\r\n",
        "            sum += 1\r\n",
        "    df_test_day.loc[t, 'päiv'] = sum\r\n",
        "df_test_day['JOL1'] = pd.DataFrame([pd.arrays.IntervalArray(df_test_day['timespan']).contains(b) for b in df_test[df_test.jatkoh_laitos_nimi == 'JOL1'].loppuhetki]).sum()\r\n",
        "df_test_day['koti'] = pd.DataFrame([pd.arrays.IntervalArray(df_test_day['timespan']).contains(b) for b in df_test[df_test.jh_selite == 'Koti'].loppuhetki]).sum()\r\n",
        "df_test_day['muu'] = pd.DataFrame([pd.arrays.IntervalArray(df_test_day['timespan']).contains(b) for b in df_test[(df_test.jh_selite != 'Koti') & (df_test.jatkoh_laitos_nimi != 'JOL1')].loppuhetki]).sum()\r\n",
        "df_test_day.set_index('time', inplace=True)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582823775
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_day['päiv_prob_00'] = df_test_day.iloc[::3, :].päiv / df_test_day.iloc[::3, :].patient_count\r\n",
        "df_test_day['päiv_prob_08'] = df_test_day.iloc[1::3, :].päiv / df_test_day.iloc[1::3, :].patient_count\r\n",
        "df_test_day['päiv_prob_16'] = df_test_day.iloc[2::3, :].päiv / df_test_day.iloc[2::3, :].patient_count\r\n",
        "df_test_day['JOL1_prob_00'] = df_test_day.iloc[::3, :].JOL1 / df_test_day.iloc[::3, :].patient_count\r\n",
        "df_test_day['JOL1_prob_08'] = df_test_day.iloc[1::3, :].JOL1 / df_test_day.iloc[1::3, :].patient_count\r\n",
        "df_test_day['JOL1_prob_16'] = df_test_day.iloc[2::3, :].JOL1 / df_test_day.iloc[2::3, :].patient_count\r\n",
        "df_test_day['koti_prob_00'] = df_test_day.iloc[::3, :].koti / df_test_day.iloc[::3, :].patient_count\r\n",
        "df_test_day['koti_prob_08'] = df_test_day.iloc[1::3, :].koti / df_test_day.iloc[1::3, :].patient_count\r\n",
        "df_test_day['koti_prob_16'] = df_test_day.iloc[2::3, :].koti / df_test_day.iloc[2::3, :].patient_count\r\n",
        "df_test_day['muu_prob_00'] = df_test_day.iloc[::3, :].muu / df_test_day.iloc[::3, :].patient_count\r\n",
        "df_test_day['muu_prob_08'] = df_test_day.iloc[1::3, :].muu / df_test_day.iloc[1::3, :].patient_count\r\n",
        "df_test_day['muu_prob_16'] = df_test_day.iloc[2::3, :].muu / df_test_day.iloc[2::3, :].patient_count\r\n",
        "\r\n",
        "df_test_day_grouped = df_test_day.groupby(by='weekday')\r\n",
        "train_mean = df_test_day_grouped.mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00', \r\n",
        "    'päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08', 'päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582824321
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics(test_df, columns):\r\n",
        "    result_df = pd.DataFrame()\r\n",
        "    for i, j in zip(3*list(range(0, 12, 4)), range(12, 48, 4)):\r\n",
        "        mape = mean_absolute_percentage_error(test_df.iloc[:, i:i+4], test_df.iloc[:, j:j+4])\r\n",
        "        mae = mean_absolute_error(test_df.iloc[:, i:i+4], test_df.iloc[:, j:j+4])\r\n",
        "        mse = mean_squared_error(test_df.iloc[:, i:i+4], test_df.iloc[:, j:j+4])\r\n",
        "        rmse = np.sqrt(mse)\r\n",
        "        result_df = pd.concat([result_df, mape, mae, rmse], axis=1)\r\n",
        "\r\n",
        "    mean_df = result_df.mean(axis=0)\r\n",
        "    mean_df.index = ['MAPE', 'MAE', 'RMSE'] * 9\r\n",
        "    mean_mape_df = result_df.loc[columns]\r\n",
        "    mean_df.iloc[list(range(0, 27, 3))] = mean_mape_df.iloc[:, list(range(0, 27, 3))].mean(axis=0)\r\n",
        "    mean_by_day_df = pd.DataFrame()\r\n",
        "    for i in range(0, 27, 9):\r\n",
        "        mean_by_day_df = pd.concat([mean_by_day_df, pd.DataFrame(np.mean([mean_df[0+i:3+i], mean_df[3+i:6+i], mean_df[6+i:9+i]], axis=0))])\r\n",
        "    mean_by_day_df.index = ['MAPE', 'MAE', 'RMSE'] * 3\r\n",
        "    return mean_df, mean_by_day_df\r\n",
        "\r\n",
        "def smoothen_transition_probs(df_mean):\r\n",
        "    for row in range(len(df_mean)):\r\n",
        "        probs_sum = np.sum([df_mean.at[row, n] for n in df_mean.columns])\r\n",
        "        for names in df_mean.columns:\r\n",
        "            df_mean.loc[df_mean.index == row, names] = df_mean.loc[df_mean.index == row, names] / probs_sum + 0.000000001\r\n",
        "    return df_mean"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582826235
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensimmäinen ennusteajankohta 22.1.-11.2.2019: toteutuneiden ja 3kk, 2kk ja 1kk historiadatan avulla laskettujen siirtymätodennäköisyyksien erot"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_true_midnight = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-01-22')) & (df_test_day.index < pd.Timestamp('2019-02-12'))].groupby(by='weekday').mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "test_true_day = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-01-22')) & (df_test_day.index < pd.Timestamp('2019-02-12'))].groupby(by='weekday').mean()[['päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "test_true_night = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-01-22')) & (df_test_day.index < pd.Timestamp('2019-02-12'))].groupby(by='weekday').mean()[['päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']])\r\n",
        "\r\n",
        "test_first_midnight = smoothen_transition_probs(df_test_day[df_test_day.index < pd.Timestamp('2019-01-01')].groupby(by='weekday').mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "test_first_day = smoothen_transition_probs(df_test_day[df_test_day.index < pd.Timestamp('2019-01-01')].groupby(by='weekday').mean()[['päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "test_first_night = smoothen_transition_probs(df_test_day[df_test_day.index < pd.Timestamp('2019-01-01')].groupby(by='weekday').mean()[['päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']])   \r\n",
        "\r\n",
        "test_second_midnight = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2018-11-01')) & (df_test_day.index < pd.Timestamp('2019-01-01'))].groupby(by='weekday').mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "test_second_day = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2018-11-01')) & (df_test_day.index < pd.Timestamp('2019-01-01'))].groupby(by='weekday').mean()[['päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "test_second_night = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2018-11-01')) & (df_test_day.index < pd.Timestamp('2019-01-01'))].groupby(by='weekday').mean()[['päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]) \r\n",
        "\r\n",
        "test_third_midnight = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2018-12-01')) & (df_test_day.index < pd.Timestamp('2019-01-01'))].groupby(by='weekday').mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "test_third_day = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2018-12-01')) & (df_test_day.index < pd.Timestamp('2019-01-01'))].groupby(by='weekday').mean()[['päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "test_third_night = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2018-12-01')) & (df_test_day.index < pd.Timestamp('2019-01-01'))].groupby(by='weekday').mean()[['päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]) \r\n",
        "\r\n",
        "test_df = pd.concat([test_true_midnight, test_true_day, test_true_night, test_first_midnight, test_first_day, test_first_night, test_second_midnight, test_second_day, test_second_night, test_third_midnight, test_third_day, test_third_night], axis=1)\r\n",
        "results_mean, results_mean_day = metrics(test_df, ['päiv_prob_00', 'JOL1_prob_00', 'koti_prob_00', 'päiv_prob_08', 'JOL1_prob_08', 'koti_prob_08', 'päiv_prob_16', 'JOL1_prob_16', 'koti_prob_16'])"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582826684
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_mean_day"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "              0\nMAPE  24.865232\nMAE    0.033737\nRMSE   0.040741\nMAPE  24.324924\nMAE    0.032109\nRMSE   0.038303\nMAPE  28.992920\nMAE    0.034908\nRMSE   0.041698",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MAPE</th>\n      <td>24.865232</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>0.033737</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>0.040741</td>\n    </tr>\n    <tr>\n      <th>MAPE</th>\n      <td>24.324924</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>0.032109</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>0.038303</td>\n    </tr>\n    <tr>\n      <th>MAPE</th>\n      <td>28.992920</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>0.034908</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>0.041698</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582827194
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Toinen ennusteajankohta 22.3.-11.4.2019: toteutuneiden ja 3kk, 2kk ja 1kk historiadatan avulla laskettujen siirtymätodennäköisyyksien erot"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_true_midnight = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-03-22')) & (df_test_day.index < pd.Timestamp('2019-04-12'))].groupby(by='weekday').mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "test_true_day = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-03-22')) & (df_test_day.index < pd.Timestamp('2019-04-12'))].groupby(by='weekday').mean()[['päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "test_true_night = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-03-22')) & (df_test_day.index < pd.Timestamp('2019-04-12'))].groupby(by='weekday').mean()[['päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']])\r\n",
        "\r\n",
        "test_first_midnight = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2018-12-01')) & (df_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "test_first_day = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2018-12-01')) & (df_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "test_first_night = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2018-12-01')) & (df_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']])   \r\n",
        "\r\n",
        "test_second_midnight = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-01-01')) & (df_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "test_second_day = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-01-01')) & (df_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "test_second_night = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-01-01')) & (df_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]) \r\n",
        "\r\n",
        "test_third_midnight = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-02-01')) & (df_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "test_third_day = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-02-01')) & (df_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "test_third_night = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-02-01')) & (df_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]) \r\n",
        "\r\n",
        "test_df = pd.concat([test_true_midnight, test_true_day, test_true_night, test_first_midnight, test_first_day, test_first_night, test_second_midnight, test_second_day, test_second_night, test_third_midnight, test_third_day, test_third_night], axis=1)\r\n",
        "results_mean, results_mean_day = metrics(test_df, ['päiv_prob_00', 'JOL1_prob_00', 'koti_prob_00', 'päiv_prob_08', 'JOL1_prob_08', 'koti_prob_08', 'päiv_prob_16', 'JOL1_prob_16', 'koti_prob_16'])\r\n"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582827658
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_mean_day"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "              0\nMAPE  31.032463\nMAE    0.044841\nRMSE   0.054388\nMAPE  35.745771\nMAE    0.047296\nRMSE   0.057273\nMAPE  40.406838\nMAE    0.051877\nRMSE   0.063320",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MAPE</th>\n      <td>31.032463</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>0.044841</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>0.054388</td>\n    </tr>\n    <tr>\n      <th>MAPE</th>\n      <td>35.745771</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>0.047296</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>0.057273</td>\n    </tr>\n    <tr>\n      <th>MAPE</th>\n      <td>40.406838</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>0.051877</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>0.063320</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582828870
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kolmas ennusteajankohta 22.11.-12.12.2019: toteutuneiden ja 3kk, 2kk ja 1kk historiadatan avulla laskettujen siirtymätodennäköisyyksien erot"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_true_midnight = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-11-22')) & (df_test_day.index < pd.Timestamp('2019-12-13'))].groupby(by='weekday').mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "test_true_day = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-11-22')) & (df_test_day.index < pd.Timestamp('2019-12-13'))].groupby(by='weekday').mean()[['päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "test_true_night = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-11-22')) & (df_test_day.index < pd.Timestamp('2019-12-13'))].groupby(by='weekday').mean()[['päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']])\r\n",
        "\r\n",
        "test_first_midnight = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-08-01')) & (df_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "test_first_day = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-08-01')) & (df_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "test_first_night = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-08-01')) & (df_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']])   \r\n",
        "\r\n",
        "test_second_midnight = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-09-01')) & (df_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "test_second_day = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-09-01')) & (df_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "test_second_night = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-09-01')) & (df_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]) \r\n",
        "\r\n",
        "test_third_midnight = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-10-01')) & (df_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['päiv_prob_00', 'JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "test_third_day = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-10-01')) & (df_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['päiv_prob_08', 'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "test_third_night = smoothen_transition_probs(df_test_day[(df_test_day.index >= pd.Timestamp('2019-10-01')) & (df_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['päiv_prob_16', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]) \r\n",
        "\r\n",
        "test_df = pd.concat([test_true_midnight, test_true_day, test_true_night, test_first_midnight, test_first_day, test_first_night, test_second_midnight, test_second_day, test_second_night, test_third_midnight, test_third_day, test_third_night], axis=1)\r\n",
        "results_mean, results_mean_day = metrics(test_df, ['päiv_prob_00', 'JOL1_prob_00', 'koti_prob_00', 'päiv_prob_08', 'JOL1_prob_08', 'koti_prob_08', 'päiv_prob_16', 'JOL1_prob_16', 'koti_prob_16'])"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582829338
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_mean_day"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "                 0\nMAPE  1.172279e+08\nMAE   4.344077e-02\nRMSE  5.429570e-02\nMAPE  1.573368e+08\nMAE   4.364286e-02\nRMSE  5.438999e-02\nMAPE  2.378548e+08\nMAE   4.616305e-02\nRMSE  5.842255e-02",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MAPE</th>\n      <td>1.172279e+08</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>4.344077e-02</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>5.429570e-02</td>\n    </tr>\n    <tr>\n      <th>MAPE</th>\n      <td>1.573368e+08</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>4.364286e-02</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>5.438999e-02</td>\n    </tr>\n    <tr>\n      <th>MAPE</th>\n      <td>2.378548e+08</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>4.616305e-02</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>5.842255e-02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582829858
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# L1"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subscription_id = '4371739e-d07f-42d5-a3a6-efa120c1e246'\r\n",
        "resource_group = 'husfd-tu-dip-potilasvirrat'\r\n",
        "workspace_name = 'husfd-tu-dip-potilasvirrat-ml'\r\n",
        "\r\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\r\n",
        "\r\n",
        "dataset_ward = Dataset.get_by_name(workspace, name='uranus27_2')\r\n",
        "features_ward = ['henkilotunnus', 'alkuhetki', 'loppuhetki', 'vo_toimipiste_nimi', 'pot_eala_selite', 'paadg_oire_selite', 'mista_lah_tuli_koodi',\r\n",
        "       'mista_lah_tuli_nimi', 'mista_tuli_koodi', 'mista_tuli_selite', 'jatkoh_laitos_nimi',\r\n",
        "       'jatkoh_toimipiste_nimi', 'jh_koodi', 'jh_selite', 'osastohoito_numero', 'shjakso_numero']\r\n",
        "ward = dataset_ward.to_pandas_dataframe()[features_ward]\r\n",
        "ward.replace(\"\", float(\"NaN\"), inplace=True)\r\n",
        "ward.dropna(subset=['alkuhetki', 'loppuhetki'], inplace=True)\r\n",
        "ward.drop_duplicates(subset='osastohoito_numero', inplace=True)\r\n",
        "ward = ward[(ward.alkuhetki >= start) & (ward.alkuhetki < end)]\r\n",
        "ward_train = ward\r\n",
        "ward_test = ward[ward.alkuhetki >= train_test_day]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582832023
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ward_train['alkuhetki'] = pd.to_datetime(ward_train['alkuhetki'], format=\"%Y-%m-%d %H:%M:%S\")\r\n",
        "ward_train['loppuhetki'] = pd.to_datetime(ward_train['loppuhetki'], format=\"%Y-%m-%d %H:%M:%S\")\r\n",
        "ward_train = ward_train[ward_train['alkuhetki'] <= ward_train['loppuhetki']]\r\n",
        "ward_train['aikaväli'] = pd.arrays.IntervalArray.from_arrays(left = ward_train['alkuhetki'], right = ward_train['loppuhetki'], closed='neither')\r\n",
        "ward_train['palveluaika'] = np.round(((ward_train['loppuhetki'] - ward_train['alkuhetki']).astype('timedelta64[s]') / 3600 / 24))\r\n",
        "ward_train['alku'] = ward_train.alkuhetki\r\n",
        "ward_train['loppu'] = ward_train.loppuhetki\r\n",
        "ward_train.reset_index(drop=True, inplace=True)"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582832550
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ward_test['alkuhetki'] = pd.to_datetime(ward_test['alkuhetki'], format=\"%Y-%m-%d %H:%M:%S\")\r\n",
        "ward_test['loppuhetki'] = pd.to_datetime(ward_test['loppuhetki'], format=\"%Y-%m-%d %H:%M:%S\")\r\n",
        "ward_test = ward_test[ward_test['alkuhetki'] <= ward_test['loppuhetki']]\r\n",
        "ward_test['aikaväli'] = pd.arrays.IntervalArray.from_arrays(left = ward_test['alkuhetki'], right = ward_test['loppuhetki'], closed='neither')\r\n",
        "ward_test['palveluaika'] = np.round(((ward_test['loppuhetki'] - ward_test['alkuhetki']).astype('timedelta64[s]') / 3600 / 24))\r\n",
        "ward_test['alku'] = ward_test.alkuhetki\r\n",
        "ward_test['loppu'] = ward_test.loppuhetki\r\n",
        "ward_test.reset_index(drop=True, inplace=True)"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582836981
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aika = train_test_day\r\n",
        "span_day = pd.DataFrame(data={'time':[aika + timedelta(hours=x) for x in range(0, const3, 8)]})\r\n",
        "timestamp_day = [aika + timedelta(hours=x) for x in range(0, const4, 8)]\r\n",
        "ward_test_day = pd.DataFrame(data={'time':timestamp_day})\r\n",
        "ward_test_day['weekday'] = ward_test_day['time'].dt.weekday\r\n",
        "ward_test_day['month'] = ward_test_day['time'].dt.month\r\n",
        "ward_test_day['timespan'] = pd.arrays.IntervalArray.from_arrays(left = span_day['time'][0:-1], right = span_day['time'][1:], closed='left')\r\n",
        "ward_test_day['patient_count'] = pd.DataFrame([pd.arrays.IntervalArray(ward_test_day['timespan']).overlaps(b) for b in ward_test['aikaväli']]).sum()\r\n",
        "\r\n",
        "for t in range(len(ward_test_day['timespan'])):\r\n",
        "    sum = 0\r\n",
        "    for a, b in zip(ward_test['aikaväli'], ward_test['loppuhetki']):\r\n",
        "        if ((ward_test_day.loc[t, 'timespan'].overlaps(a)) == True) & ((b in ward_test_day.loc[t, 'timespan']) == False):\r\n",
        "            sum += 1\r\n",
        "    ward_test_day.loc[t, 'JOL1'] = sum\r\n",
        "ward_test_day['koti'] = pd.DataFrame([pd.arrays.IntervalArray(ward_test_day['timespan']).contains(b) for b in ward_test[(ward_test.jh_selite == 'Koti')].loppuhetki]).sum()\r\n",
        "ward_test_day['muu'] = pd.DataFrame([pd.arrays.IntervalArray(ward_test_day['timespan']).contains(b) for b in ward_test[(ward_test.jh_selite != 'Koti')].loppuhetki]).sum()\r\n",
        "ward_test_day.set_index('time', inplace=True)"
      ],
      "outputs": [],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582979807
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ward_test_day['JOL1_prob_00'] = ward_test_day.iloc[::3, :].JOL1 / ward_test_day.iloc[::3, :].patient_count\r\n",
        "ward_test_day['JOL1_prob_08'] = ward_test_day.iloc[1::3, :].JOL1 / ward_test_day.iloc[1::3, :].patient_count\r\n",
        "ward_test_day['JOL1_prob_16'] = ward_test_day.iloc[2::3, :].JOL1 / ward_test_day.iloc[2::3, :].patient_count\r\n",
        "ward_test_day['koti_prob_00'] = ward_test_day.iloc[::3, :].koti / ward_test_day.iloc[::3, :].patient_count\r\n",
        "ward_test_day['koti_prob_08'] = ward_test_day.iloc[1::3, :].koti / ward_test_day.iloc[1::3, :].patient_count\r\n",
        "ward_test_day['koti_prob_16'] = ward_test_day.iloc[2::3, :].koti / ward_test_day.iloc[2::3, :].patient_count\r\n",
        "ward_test_day['muu_prob_00'] = ward_test_day.iloc[::3, :].muu / ward_test_day.iloc[::3, :].patient_count\r\n",
        "ward_test_day['muu_prob_08'] = ward_test_day.iloc[1::3, :].muu / ward_test_day.iloc[1::3, :].patient_count\r\n",
        "ward_test_day['muu_prob_16'] = ward_test_day.iloc[2::3, :].muu / ward_test_day.iloc[2::3, :].patient_count\r\n",
        "ward_test_day_grouped = ward_test_day.groupby(by='weekday')\r\n",
        "ward_test_mean = ward_test_day_grouped.mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00', \r\n",
        "    'JOL1_prob_08', 'muu_prob_08', 'koti_prob_08', 'JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582980846
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics(test_df, columns):\r\n",
        "    result_df = pd.DataFrame()\r\n",
        "    for i, j in zip(3*list(range(0, 9, 3)), range(9, 36, 3)):\r\n",
        "        mape = mean_absolute_percentage_error(test_df.iloc[:, i:i+3], test_df.iloc[:, j:j+3])\r\n",
        "        mae = mean_absolute_error(test_df.iloc[:, i:i+3], test_df.iloc[:, j:j+3])\r\n",
        "        mse = mean_squared_error(test_df.iloc[:, i:i+3], test_df.iloc[:, j:j+3])\r\n",
        "        rmse = np.sqrt(mse)\r\n",
        "        result_df = pd.concat([result_df, mape, mae, rmse], axis=1)\r\n",
        "    mean_df = result_df.mean(axis=0)\r\n",
        "    mean_df.index = ['MAPE', 'MAE', 'RMSE'] * 9\r\n",
        "\r\n",
        "    mean_mape_df = result_df.loc[columns]\r\n",
        "    mean_df.iloc[list(range(0, 18, 2))] = mean_mape_df.iloc[:, list(range(0, 18, 2))].mean(axis=0)\r\n",
        "    mean_by_day_df = pd.DataFrame()\r\n",
        "    for i in range(0, 27, 9):\r\n",
        "        mean_by_day_df = pd.concat([mean_by_day_df, pd.DataFrame(np.mean([mean_df[0+i:3+i], mean_df[3+i:6+i], mean_df[6+i:9+i]], axis=0))])\r\n",
        "    mean_by_day_df.index = ['MAPE', 'MAE', 'RMSE'] * 3\r\n",
        "    return mean_df, mean_by_day_df\r\n",
        "\r\n",
        "def smoothen_transition_probs(df_mean):\r\n",
        "    for row in range(len(df_mean)):\r\n",
        "        probs_sum = np.sum([df_mean.at[row, n] for n in df_mean.columns])\r\n",
        "        for names in df_mean.columns:\r\n",
        "            df_mean.loc[df_mean.index == row, names] = df_mean.loc[df_mean.index == row, names] / probs_sum + 0.000000001\r\n",
        "    return df_mean"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582981310
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ward_true_midnight = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-01-22')) & (ward_test_day.index < pd.Timestamp('2019-02-12'))].groupby(by='weekday').mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "ward_true_day = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-01-22')) & (ward_test_day.index < pd.Timestamp('2019-02-12'))].groupby(by='weekday').mean()[['JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "ward_true_night = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-01-22')) & (ward_test_day.index < pd.Timestamp('2019-02-12'))].groupby(by='weekday').mean()[['JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']])\r\n",
        "\r\n",
        "ward_first_midnight = smoothen_transition_probs(ward_test_day[ward_test_day.index < pd.Timestamp('2019-01-01')].groupby(by='weekday').mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "ward_first_day = smoothen_transition_probs(ward_test_day[ward_test_day.index < pd.Timestamp('2019-01-01')].groupby(by='weekday').mean()[['JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "ward_first_night = smoothen_transition_probs(ward_test_day[ward_test_day.index < pd.Timestamp('2019-01-01')].groupby(by='weekday').mean()[['JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']])   \r\n",
        "\r\n",
        "ward_second_midnight = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2018-11-01')) & (ward_test_day.index < pd.Timestamp('2019-01-01'))].groupby(by='weekday').mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "ward_second_day = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2018-11-01')) & (ward_test_day.index < pd.Timestamp('2019-01-01'))].groupby(by='weekday').mean()[['JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "ward_second_night = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2018-11-01')) & (ward_test_day.index < pd.Timestamp('2019-01-01'))].groupby(by='weekday').mean()[['JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]) \r\n",
        "\r\n",
        "ward_third_midnight = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2018-12-01')) & (ward_test_day.index < pd.Timestamp('2019-01-01'))].groupby(by='weekday').mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "ward_third_day = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2018-12-01')) & (ward_test_day.index < pd.Timestamp('2019-01-01'))].groupby(by='weekday').mean()[['JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "ward_third_night = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2018-12-01')) & (ward_test_day.index < pd.Timestamp('2019-01-01'))].groupby(by='weekday').mean()[['JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]) \r\n",
        "\r\n",
        "ward_df = pd.concat([ward_true_midnight, ward_true_day, ward_true_night, ward_first_midnight, ward_first_day, ward_first_night, ward_second_midnight, ward_second_day, ward_second_night, ward_third_midnight, ward_third_day, ward_third_night], axis=1)\r\n",
        "results_mean, results_mean_day = metrics(ward_df, ['JOL1_prob_00', 'koti_prob_00', 'JOL1_prob_08', 'koti_prob_08', 'JOL1_prob_16', 'koti_prob_16'])"
      ],
      "outputs": [],
      "execution_count": 60,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681584052005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_mean_day"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 61,
          "data": {
            "text/plain": "                 0\nMAPE  7.150109e+07\nMAE   3.178688e-02\nRMSE  3.658696e-02\nMAPE  4.479160e+07\nMAE   3.010499e-02\nRMSE  3.762957e-02\nMAPE  7.237915e+07\nMAE   2.548242e-02\nRMSE  3.217127e-02",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MAPE</th>\n      <td>7.150109e+07</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>3.178688e-02</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>3.658696e-02</td>\n    </tr>\n    <tr>\n      <th>MAPE</th>\n      <td>4.479160e+07</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>3.010499e-02</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>3.762957e-02</td>\n    </tr>\n    <tr>\n      <th>MAPE</th>\n      <td>7.237915e+07</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>2.548242e-02</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>3.217127e-02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 61,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681584053906
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ward_true_midnight = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-03-22')) & (ward_test_day.index < pd.Timestamp('2019-04-12'))].groupby(by='weekday').mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "ward_true_day = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-03-22')) & (ward_test_day.index < pd.Timestamp('2019-04-12'))].groupby(by='weekday').mean()[['JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "ward_true_night = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-03-22')) & (ward_test_day.index < pd.Timestamp('2019-04-12'))].groupby(by='weekday').mean()[['JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']])\r\n",
        "\r\n",
        "ward_first_midnight = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2018-12-01')) & (ward_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "ward_first_day = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2018-12-01')) & (ward_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "ward_first_night = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2018-12-01')) & (ward_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']])   \r\n",
        "\r\n",
        "ward_second_midnight = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-01-01')) & (ward_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "ward_second_day = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-01-01')) & (ward_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "ward_second_night = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-01-01')) & (ward_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]) \r\n",
        "\r\n",
        "ward_third_midnight = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-02-01')) & (ward_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "ward_third_day = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-02-01')) & (ward_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "ward_third_night = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-02-01')) & (ward_test_day.index < pd.Timestamp('2019-03-01'))].groupby(by='weekday').mean()[['JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]) \r\n",
        "\r\n",
        "ward_df = pd.concat([ward_true_midnight, ward_true_day, ward_true_night, ward_first_midnight, ward_first_day, ward_first_night, ward_second_midnight, ward_second_day, ward_second_night, ward_third_midnight, ward_third_day, ward_third_night], axis=1)\r\n",
        "results_mean, results_mean_day = metrics(ward_df, ['JOL1_prob_00', 'koti_prob_00', 'JOL1_prob_08', 'koti_prob_08', 'JOL1_prob_16', 'koti_prob_16'])"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582982741
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_mean_day"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "                 0\nMAPE  2.053033e+08\nMAE   3.706054e-02\nRMSE  3.886835e-02\nMAPE  2.040093e+08\nMAE   3.389616e-02\nRMSE  4.459580e-02\nMAPE  3.238094e+08\nMAE   3.046996e-02\nRMSE  3.571162e-02",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MAPE</th>\n      <td>2.053033e+08</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>3.706054e-02</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>3.886835e-02</td>\n    </tr>\n    <tr>\n      <th>MAPE</th>\n      <td>2.040093e+08</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>3.389616e-02</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>4.459580e-02</td>\n    </tr>\n    <tr>\n      <th>MAPE</th>\n      <td>3.238094e+08</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>3.046996e-02</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>3.571162e-02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 46,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582983242
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ward_true_midnight = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-11-22')) & (ward_test_day.index < pd.Timestamp('2019-12-13'))].groupby(by='weekday').mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "ward_true_day = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-11-22')) & (ward_test_day.index < pd.Timestamp('2019-12-13'))].groupby(by='weekday').mean()[['JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "ward_true_night = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-11-22')) & (ward_test_day.index < pd.Timestamp('2019-12-13'))].groupby(by='weekday').mean()[['JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']])\r\n",
        "\r\n",
        "ward_first_midnight = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-08-01')) & (ward_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "ward_first_day = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-08-01')) & (ward_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "ward_first_night = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-08-01')) & (ward_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']])   \r\n",
        "\r\n",
        "ward_second_midnight = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-09-01')) & (ward_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "ward_second_day = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-09-01')) & (ward_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "ward_second_night = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-09-01')) & (ward_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]) \r\n",
        "\r\n",
        "ward_third_midnight = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-10-01')) & (ward_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['JOL1_prob_00', 'muu_prob_00', 'koti_prob_00']])\r\n",
        "ward_third_day = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-10-01')) & (ward_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['JOL1_prob_08', 'muu_prob_08', 'koti_prob_08']])\r\n",
        "ward_third_night = smoothen_transition_probs(ward_test_day[(ward_test_day.index >= pd.Timestamp('2019-10-01')) & (ward_test_day.index < pd.Timestamp('2019-11-01'))].groupby(by='weekday').mean()[['JOL1_prob_16', 'muu_prob_16', 'koti_prob_16']]) \r\n",
        "\r\n",
        "ward_df = pd.concat([ward_true_midnight, ward_true_day, ward_true_night, ward_first_midnight, ward_first_day, ward_first_night, ward_second_midnight, ward_second_day, ward_second_night, ward_third_midnight, ward_third_day, ward_third_night], axis=1)\r\n",
        "results_mean, results_mean_day = metrics(ward_df, ['JOL1_prob_00', 'koti_prob_00', 'JOL1_prob_08', 'koti_prob_08', 'JOL1_prob_16', 'koti_prob_16'])"
      ],
      "outputs": [],
      "execution_count": 47,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582983672
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_mean_day"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "                 0\nMAPE  2.004477e+08\nMAE   3.949489e-02\nRMSE  4.785082e-02\nMAPE  2.838967e+08\nMAE   4.109354e-02\nRMSE  4.944005e-02\nMAPE  3.045968e+08\nMAE   3.640902e-02\nRMSE  4.488343e-02",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MAPE</th>\n      <td>2.004477e+08</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>3.949489e-02</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>4.785082e-02</td>\n    </tr>\n    <tr>\n      <th>MAPE</th>\n      <td>2.838967e+08</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>4.109354e-02</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>4.944005e-02</td>\n    </tr>\n    <tr>\n      <th>MAPE</th>\n      <td>3.045968e+08</td>\n    </tr>\n    <tr>\n      <th>MAE</th>\n      <td>3.640902e-02</td>\n    </tr>\n    <tr>\n      <th>RMSE</th>\n      <td>4.488343e-02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 48,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681582984155
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK V2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}